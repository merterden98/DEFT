{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpc/group/singhlab/rawdata/afdbMert/jay/208964/208964_4f726a52-f94b-4a2b-80ee-d3287f5068fd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://public-datasets-deepmind-alphafold-v4/proteomes/proteome-tax_id-208964-0_v4.tar...\n",
      "/ [1/1 files][649.2 MiB/649.2 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/649.2 MiB.                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpc/group/singhlab/rawdata/afdbMert/jay/208964/208964_4f726a52-f94b-4a2b-80ee-d3287f5068fd\n",
      "running foldseek\n",
      "foldseek easy-search --cov-mode 2 -e 0.1 /hpc/group/singhlab/rawdata/afdbMert/jay/208964/208964_4f726a52-f94b-4a2b-80ee-d3287f5068fd /hpc/group/singhlab/rawdata/afdbMert/clean70_0/clean70_db /hpc/group/singhlab/rawdata/afdbMert/jay/208964208964_aln.m8 /hpc/group/singhlab/user/me196/tmp/tmpu1bmsuzn/aln8213069190711167087\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from cli import CreateDatasetSpecies\n",
    "from glob import glob\n",
    "FILE = \"recon_microbe.tsv\"\n",
    "TRAIN_DB = \"/hpc/group/singhlab/rawdata/afdbMert/clean70_0/clean70_db\"\n",
    "output = \"/hpc/group/singhlab/rawdata/afdbMert/jay\"\n",
    "\n",
    "\n",
    "ids = [208964]\n",
    "\n",
    "computed = set()\n",
    "\n",
    "\n",
    "for i in ids:\n",
    "    species = int(i)\n",
    "    if species in computed:\n",
    "        continue\n",
    "    else:\n",
    "        create_dataset = CreateDatasetSpecies(species, f\"{output}/{species}\", TRAIN_DB)\n",
    "        create_dataset.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9581662728e4b32a7ce711bb2720ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 208964\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from cli import Predict\n",
    "from glob import glob\n",
    "FILE = \"recon_microbe.tsv\"\n",
    "TRAIN_DB = \"/hpc/group/singhlab/rawdata/afdbMert/clean70_0/clean70_db\"\n",
    "TRAIN_CSV = \"/hpc/group/singhlab/rawdata/afdbMert/clean70_0/clean70_0_res.csv\"\n",
    "output = \"/hpc/group/singhlab/rawdata/afdbMert/jay\"\n",
    "model = \"../models/\"\n",
    "PEFT = \"/hpc/group/singhlab/rawdata/afdbMert/clean70_0_model/\"\n",
    "ids = [208964]\n",
    "\n",
    "for id in ids:\n",
    "    data = f\"{output}/{id}/{id}_res.csv\"\n",
    "    aln = glob(f\"{output}/{id}*_aln.m8\")[0]\n",
    "    p = Predict(data, aln,model, PEFT,TRAIN_CSV)\n",
    "\n",
    "    pred = p.run()\n",
    "    pred.to_csv(f\"{output}/{id}/{id}_pred.csv\", index=False)\n",
    "    print(\"Done with {}\".format(id))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECS_OF_INTEREST = [\"1.14.12.12\", \"1.14.15.3\", \"4.1.99.11\", \"1.14.13.243\", \"1.14.12.11\", \"1.14.15.26\"]\n",
    "from collections import defaultdict\n",
    "results = defaultdict(lambda: defaultdict(list))\n",
    "for id in ids:\n",
    "    df = pd.read_csv(f\"{output}/{id}/{id}_pred.csv\")\n",
    "    for ecs in ECS_OF_INTEREST:\n",
    "        results[ecs][\"id\"].append(id)\n",
    "        pred = df[df[\"EC\"] == ecs]\n",
    "        # extract Query Target and Bits\n",
    "        pred = pred[[\"Query\", \"Target\", \"Bits\"]]\n",
    "        results[ecs][\"pred\"].append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 208964\n",
      "No Match\n",
      "Results for 208964\n",
      "Results for 208964\n",
      "No Match\n",
      "Results for 208964\n",
      "No Match\n",
      "Results for 208964\n",
      "No Match\n",
      "Results for 208964\n",
      "No Match\n"
     ]
    }
   ],
   "source": [
    "with open(\"results.txt\", \"w\") as f:\n",
    "    for ecs in ECS_OF_INTEREST:\n",
    "        f.write(f\"Results for {ecs}\\n\\n\")\n",
    "        for i, id in enumerate(results[ecs][\"id\"]):\n",
    "            print(f\"Results for {id}\")\n",
    "            # If results[ecs][\"pred\"][i] is empty print No Match\n",
    "            if results[ecs][\"pred\"][i].empty:\n",
    "                print(\"No Match\")\n",
    "                continue\n",
    "            else:\n",
    "                f.write(f\"\\tOn Taxon Id {id}\\n\")\n",
    "                f.write(results[ecs][\"pred\"][i].to_string())\n",
    "                f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SaProt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
